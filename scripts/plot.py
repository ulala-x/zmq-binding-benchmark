#!/usr/bin/env python3

"""
ZeroMQ Binding Benchmark - Visualization
Generates comparison plots from benchmark data
"""

import json
import sys
from pathlib import Path

try:
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    import numpy as np
except ImportError:
    print("Error: matplotlib is not installed")
    print("Install with: pip3 install matplotlib")
    sys.exit(1)


def format_large_number(value, pos=None):
    """Format large numbers with K/M suffix"""
    if value >= 1_000_000:
        return f"{value/1_000_000:.1f}M"
    elif value >= 1_000:
        return f"{value/1_000:.0f}K"
    else:
        return f"{value:.0f}"


def plot_latency_comparison(data, output_dir):
    """Generate latency comparison bar chart"""
    # Extract data
    languages = ["C++", ".NET", "Node.js"]
    colors = ["#3498db", "#2ecc71", "#e74c3c"]

    # Get message sizes
    sizes = sorted(set(item["size"] for item in data["latency"]["C++"]))
    size_labels = [f"{s}B" if s < 1024 else f"{s//1024}KB" for s in sizes]

    # Prepare data for plotting
    latencies = {lang: [] for lang in languages}

    for size in sizes:
        for lang in languages:
            lat_data = next(
                (x["latency_us"] for x in data["latency"][lang] if x["size"] == size),
                None,
            )
            latencies[lang].append(lat_data if lat_data else 0)

    # Create plot
    fig, ax = plt.subplots(figsize=(12, 6))

    x = np.arange(len(sizes))
    width = 0.25

    for idx, lang in enumerate(languages):
        offset = (idx - 1) * width
        bars = ax.bar(
            x + offset,
            latencies[lang],
            width,
            label=lang,
            color=colors[idx],
            alpha=0.8,
        )

        # Add value labels on bars
        for bar in bars:
            height = bar.get_height()
            if height > 0:
                ax.text(
                    bar.get_x() + bar.get_width() / 2.0,
                    height,
                    f"{height:.1f}",
                    ha="center",
                    va="bottom",
                    fontsize=9,
                )

    ax.set_xlabel("Message Size", fontsize=12, fontweight="bold")
    ax.set_ylabel("Latency (Î¼s)", fontsize=12, fontweight="bold")
    ax.set_title(
        "ZeroMQ Binding Latency Comparison\n(Lower is Better)",
        fontsize=14,
        fontweight="bold",
    )
    ax.set_xticks(x)
    ax.set_xticklabels(size_labels)
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3, axis="y")

    plt.tight_layout()
    output_file = output_dir / "latency_comparison.png"
    plt.savefig(output_file, dpi=300, bbox_inches="tight")
    print(f"  âœ“ Latency chart saved to: {output_file}")
    plt.close()


def plot_throughput_comparison(data, output_dir):
    """Generate throughput comparison charts"""
    languages = ["C++", ".NET", "Node.js"]
    colors = ["#3498db", "#2ecc71", "#e74c3c"]

    # Get message sizes
    sizes = sorted(set(item["size"] for item in data["throughput"]["C++"]))
    size_labels = [f"{s}B" if s < 1024 else f"{s//1024}KB" for s in sizes]

    # Prepare data
    msg_per_sec = {lang: [] for lang in languages}
    mbps = {lang: [] for lang in languages}

    for size in sizes:
        for lang in languages:
            thr_data = next(
                (x for x in data["throughput"][lang] if x["size"] == size),
                None,
            )
            if thr_data:
                msg_per_sec[lang].append(thr_data["msg_per_sec"])
                mbps[lang].append(thr_data["mbps"])
            else:
                msg_per_sec[lang].append(0)
                mbps[lang].append(0)

    # Create subplots
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))

    x = np.arange(len(sizes))
    width = 0.25

    # Plot 1: Messages per second
    for idx, lang in enumerate(languages):
        offset = (idx - 1) * width
        bars = ax1.bar(
            x + offset,
            msg_per_sec[lang],
            width,
            label=lang,
            color=colors[idx],
            alpha=0.8,
        )

        # Add value labels
        for bar in bars:
            height = bar.get_height()
            if height > 0:
                ax1.text(
                    bar.get_x() + bar.get_width() / 2.0,
                    height,
                    format_large_number(height),
                    ha="center",
                    va="bottom",
                    fontsize=9,
                )

    ax1.set_xlabel("Message Size", fontsize=12, fontweight="bold")
    ax1.set_ylabel("Messages/sec", fontsize=12, fontweight="bold")
    ax1.set_title(
        "ZeroMQ Binding Throughput Comparison - Messages per Second\n(Higher is Better)",
        fontsize=14,
        fontweight="bold",
    )
    ax1.set_xticks(x)
    ax1.set_xticklabels(size_labels)
    ax1.legend(fontsize=11)
    ax1.grid(True, alpha=0.3, axis="y")
    ax1.yaxis.set_major_formatter(ticker.FuncFormatter(format_large_number))

    # Plot 2: Bandwidth (Mb/s)
    for idx, lang in enumerate(languages):
        offset = (idx - 1) * width
        bars = ax2.bar(
            x + offset,
            mbps[lang],
            width,
            label=lang,
            color=colors[idx],
            alpha=0.8,
        )

        # Add value labels
        for bar in bars:
            height = bar.get_height()
            if height > 0:
                ax2.text(
                    bar.get_x() + bar.get_width() / 2.0,
                    height,
                    format_large_number(height),
                    ha="center",
                    va="bottom",
                    fontsize=9,
                )

    ax2.set_xlabel("Message Size", fontsize=12, fontweight="bold")
    ax2.set_ylabel("Bandwidth (Mb/s)", fontsize=12, fontweight="bold")
    ax2.set_title(
        "ZeroMQ Binding Throughput Comparison - Bandwidth\n(Higher is Better)",
        fontsize=14,
        fontweight="bold",
    )
    ax2.set_xticks(x)
    ax2.set_xticklabels(size_labels)
    ax2.legend(fontsize=11)
    ax2.grid(True, alpha=0.3, axis="y")
    ax2.yaxis.set_major_formatter(ticker.FuncFormatter(format_large_number))

    plt.tight_layout()
    output_file = output_dir / "throughput_comparison.png"
    plt.savefig(output_file, dpi=300, bbox_inches="tight")
    print(f"  âœ“ Throughput chart saved to: {output_file}")
    plt.close()


def plot_overhead_analysis(data, output_dir):
    """Generate overhead analysis chart"""
    sizes = sorted(set(item["size"] for item in data["latency"]["C++"]))
    size_labels = [f"{s}B" if s < 1024 else f"{s//1024}KB" for s in sizes]

    # Calculate overhead percentages
    dotnet_overhead = []
    nodejs_overhead = []

    for size in sizes:
        cpp_lat = next((x["latency_us"] for x in data["latency"]["C++"] if x["size"] == size), None)
        dotnet_lat = next((x["latency_us"] for x in data["latency"][".NET"] if x["size"] == size), None)
        nodejs_lat = next((x["latency_us"] for x in data["latency"]["Node.js"] if x["size"] == size), None)

        if cpp_lat and dotnet_lat:
            dotnet_overhead.append(((dotnet_lat - cpp_lat) / cpp_lat) * 100)
        else:
            dotnet_overhead.append(0)

        if cpp_lat and nodejs_lat:
            nodejs_overhead.append(((nodejs_lat - cpp_lat) / cpp_lat) * 100)
        else:
            nodejs_overhead.append(0)

    # Create plot
    fig, ax = plt.subplots(figsize=(12, 7))

    x = np.arange(len(sizes))
    width = 0.35

    bars1 = ax.bar(
        x - width / 2,
        dotnet_overhead,
        width,
        label=".NET",
        color="#2ecc71",
        alpha=0.8,
    )
    bars2 = ax.bar(
        x + width / 2,
        nodejs_overhead,
        width,
        label="Node.js",
        color="#e74c3c",
        alpha=0.8,
    )

    # Add value labels
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            label = f"{height:+.1f}%"
            va = "bottom" if height >= 0 else "top"
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                height,
                label,
                ha="center",
                va=va,
                fontsize=10,
                fontweight="bold",
            )

    ax.set_xlabel("Message Size", fontsize=12, fontweight="bold")
    ax.set_ylabel("Overhead vs C++ Baseline (%)", fontsize=12, fontweight="bold")
    ax.set_title(
        "Latency Overhead Comparison vs C++ Baseline\n(Negative = Faster than C++)",
        fontsize=14,
        fontweight="bold",
    )
    ax.set_xticks(x)
    ax.set_xticklabels(size_labels)
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3, axis="y")
    ax.axhline(y=0, color="black", linestyle="-", linewidth=1)

    plt.tight_layout()
    output_file = output_dir / "overhead_comparison.png"
    plt.savefig(output_file, dpi=300, bbox_inches="tight")
    print(f"  âœ“ Overhead chart saved to: {output_file}")
    plt.close()


def plot_dashboard(data, output_dir):
    """Generate comprehensive dashboard with all metrics"""
    fig = plt.figure(figsize=(20, 12))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

    languages = ["C++", ".NET", "Node.js"]
    colors = ["#3498db", "#2ecc71", "#e74c3c"]
    sizes = sorted(set(item["size"] for item in data["latency"]["C++"]))
    size_labels = [f"{s}B" if s < 1024 else f"{s//1024}KB" for s in sizes]

    # 1. Latency Comparison (Top Left)
    ax1 = fig.add_subplot(gs[0, 0])
    latencies = {lang: [next(x["latency_us"] for x in data["latency"][lang] if x["size"] == size)
                        for size in sizes] for lang in languages}
    x = np.arange(len(sizes))
    width = 0.25
    for idx, lang in enumerate(languages):
        offset = (idx - 1) * width
        bars = ax1.bar(x + offset, latencies[lang], width, label=lang, color=colors[idx], alpha=0.8)
        for bar in bars:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}',
                    ha='center', va='bottom', fontsize=8)
    ax1.set_xlabel('Message Size', fontweight='bold')
    ax1.set_ylabel('Latency (Î¼s)', fontweight='bold')
    ax1.set_title('Latency Comparison\n(Lower is Better)', fontweight='bold', fontsize=11)
    ax1.set_xticks(x)
    ax1.set_xticklabels(size_labels)
    ax1.legend(fontsize=9)
    ax1.grid(True, alpha=0.3, axis='y')

    # 2. Throughput (msg/s) (Top Center)
    ax2 = fig.add_subplot(gs[0, 1])
    msg_per_sec = {lang: [next(x["msg_per_sec"] for x in data["throughput"][lang] if x["size"] == size)
                          for size in sizes] for lang in languages}
    for idx, lang in enumerate(languages):
        offset = (idx - 1) * width
        bars = ax2.bar(x + offset, [m/1_000_000 for m in msg_per_sec[lang]], width,
                      label=lang, color=colors[idx], alpha=0.8)
        for bar in bars:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height, f'{height:.2f}M',
                    ha='center', va='bottom', fontsize=8)
    ax2.set_xlabel('Message Size', fontweight='bold')
    ax2.set_ylabel('Throughput (Million msg/s)', fontweight='bold')
    ax2.set_title('Throughput Comparison\n(Higher is Better)', fontweight='bold', fontsize=11)
    ax2.set_xticks(x)
    ax2.set_xticklabels(size_labels)
    ax2.legend(fontsize=9)
    ax2.grid(True, alpha=0.3, axis='y')

    # 3. Bandwidth (Top Right)
    ax3 = fig.add_subplot(gs[0, 2])
    mbps = {lang: [next(x["mbps"] for x in data["throughput"][lang] if x["size"] == size)
                   for size in sizes] for lang in languages}
    for idx, lang in enumerate(languages):
        offset = (idx - 1) * width
        bars = ax3.bar(x + offset, [m/1000 for m in mbps[lang]], width,
                      label=lang, color=colors[idx], alpha=0.8)
        for bar in bars:
            height = bar.get_height()
            if height < 1:
                label = f'{height*1000:.0f}M'
            else:
                label = f'{height:.1f}G'
            ax3.text(bar.get_x() + bar.get_width()/2., height, label,
                    ha='center', va='bottom', fontsize=8)
    ax3.set_xlabel('Message Size', fontweight='bold')
    ax3.set_ylabel('Bandwidth (Gb/s)', fontweight='bold')
    ax3.set_title('Bandwidth Comparison\n(Higher is Better)', fontweight='bold', fontsize=11)
    ax3.set_xticks(x)
    ax3.set_xticklabels(size_labels)
    ax3.legend(fontsize=9)
    ax3.grid(True, alpha=0.3, axis='y')

    # 4. Latency Overhead (Middle Left)
    ax4 = fig.add_subplot(gs[1, 0])
    cpp_lat = [next(x["latency_us"] for x in data["latency"]["C++"] if x["size"] == size) for size in sizes]
    for idx, lang in enumerate([".NET", "Node.js"]):
        lang_lat = [next(x["latency_us"] for x in data["latency"][lang] if x["size"] == size) for size in sizes]
        overhead = [((l - c) / c * 100) for l, c in zip(lang_lat, cpp_lat)]
        ax4.plot(size_labels, overhead, marker='o', linewidth=2, markersize=8,
                label=lang, color=colors[idx+1])
        for i, val in enumerate(overhead):
            ax4.annotate(f'{val:+.1f}%', xy=(i, val), xytext=(0, 10),
                        textcoords='offset points', ha='center', fontsize=8, fontweight='bold')
    ax4.axhline(y=0, color='black', linestyle='--', linewidth=1)
    ax4.set_xlabel('Message Size', fontweight='bold')
    ax4.set_ylabel('Overhead vs C++ (%)', fontweight='bold')
    ax4.set_title('Latency Overhead Analysis\n(Negative = Faster)', fontweight='bold', fontsize=11)
    ax4.legend(fontsize=9)
    ax4.grid(True, alpha=0.3)

    # 5. Throughput Overhead (Middle Center)
    ax5 = fig.add_subplot(gs[1, 1])
    cpp_thr = [next(x["msg_per_sec"] for x in data["throughput"]["C++"] if x["size"] == size) for size in sizes]
    for idx, lang in enumerate([".NET", "Node.js"]):
        lang_thr = [next(x["msg_per_sec"] for x in data["throughput"][lang] if x["size"] == size) for size in sizes]
        overhead = [((l - c) / c * 100) for l, c in zip(lang_thr, cpp_thr)]
        ax5.plot(size_labels, overhead, marker='o', linewidth=2, markersize=8,
                label=lang, color=colors[idx+1])
        for i, val in enumerate(overhead):
            ax5.annotate(f'{val:+.1f}%', xy=(i, val), xytext=(0, 10),
                        textcoords='offset points', ha='center', fontsize=8, fontweight='bold')
    ax5.axhline(y=0, color='black', linestyle='--', linewidth=1)
    ax5.set_xlabel('Message Size', fontweight='bold')
    ax5.set_ylabel('Difference vs C++ (%)', fontweight='bold')
    ax5.set_title('Throughput Difference Analysis\n(Positive = Faster)', fontweight='bold', fontsize=11)
    ax5.legend(fontsize=9)
    ax5.grid(True, alpha=0.3)

    # 6. Performance Summary Table (Middle Right)
    ax6 = fig.add_subplot(gs[1, 2])
    ax6.axis('off')

    summary_data = []
    summary_data.append(['Metric', '64B', '1.5KB', '64KB'])
    summary_data.append(['', '', '', ''])

    # C++ baseline
    summary_data.append(['C++ Latency (Î¼s)',
                        f"{latencies['C++'][0]:.1f}",
                        f"{latencies['C++'][1]:.1f}",
                        f"{latencies['C++'][2]:.1f}"])
    summary_data.append(['.NET vs C++',
                        f"{((latencies['.NET'][0] - latencies['C++'][0])/latencies['C++'][0]*100):+.1f}%",
                        f"{((latencies['.NET'][1] - latencies['C++'][1])/latencies['C++'][1]*100):+.1f}%",
                        f"{((latencies['.NET'][2] - latencies['C++'][2])/latencies['C++'][2]*100):+.1f}%"])
    summary_data.append(['Node.js vs C++',
                        f"{((latencies['Node.js'][0] - latencies['C++'][0])/latencies['C++'][0]*100):+.1f}%",
                        f"{((latencies['Node.js'][1] - latencies['C++'][1])/latencies['C++'][1]*100):+.1f}%",
                        f"{((latencies['Node.js'][2] - latencies['C++'][2])/latencies['C++'][2]*100):+.1f}%"])

    summary_data.append(['', '', '', ''])
    summary_data.append(['C++ Thr (M msg/s)',
                        f"{msg_per_sec['C++'][0]/1e6:.2f}",
                        f"{msg_per_sec['C++'][1]/1e6:.2f}",
                        f"{msg_per_sec['C++'][2]/1e6:.3f}"])
    summary_data.append(['.NET vs C++',
                        f"{((msg_per_sec['.NET'][0] - msg_per_sec['C++'][0])/msg_per_sec['C++'][0]*100):+.1f}%",
                        f"{((msg_per_sec['.NET'][1] - msg_per_sec['C++'][1])/msg_per_sec['C++'][1]*100):+.1f}%",
                        f"{((msg_per_sec['.NET'][2] - msg_per_sec['C++'][2])/msg_per_sec['C++'][2]*100):+.1f}%"])
    summary_data.append(['Node.js vs C++',
                        f"{((msg_per_sec['Node.js'][0] - msg_per_sec['C++'][0])/msg_per_sec['C++'][0]*100):+.1f}%",
                        f"{((msg_per_sec['Node.js'][1] - msg_per_sec['C++'][1])/msg_per_sec['C++'][1]*100):+.1f}%",
                        f"{((msg_per_sec['Node.js'][2] - msg_per_sec['C++'][2])/msg_per_sec['C++'][2]*100):+.1f}%"])

    table = ax6.table(cellText=summary_data, cellLoc='center', loc='center',
                     bbox=[0, 0, 1, 1])
    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1, 2)

    # Style header row
    for i in range(4):
        table[(0, i)].set_facecolor('#3498db')
        table[(0, i)].set_text_props(weight='bold', color='white')

    # Highlight key findings
    table[(3, 1)].set_facecolor('#90EE90')  # .NET 64B latency (faster)
    table[(8, 3)].set_facecolor('#90EE90')  # Node.js 64KB throughput (faster)

    ax6.set_title('Performance Summary\nvs C++ Baseline', fontweight='bold', fontsize=11, pad=20)

    # 7. Key Highlights (Bottom Span)
    ax7 = fig.add_subplot(gs[2, :])
    ax7.axis('off')

    highlights = [
        "ðŸš€ Key Findings:",
        "",
        "1. .NET 64B Latency: 53.52 Î¼s (4.6% FASTER than C++!)  â† Excellent JIT optimization",
        "",
        "2. Node.js 65KB Throughput: 113K msg/s (20.8% FASTER than C++)  â† Efficient large buffer handling",
        "",
        "3. Test Configuration: 50,000 latency rounds, 5,000,000 throughput messages",
        "",
        "4. All bindings use Message/Buffer objects (matching C++ zmq::message_t behavior)",
    ]

    y_pos = 0.9
    for line in highlights:
        if line.startswith("ðŸš€"):
            ax7.text(0.5, y_pos, line, ha='center', va='top', fontsize=14,
                    fontweight='bold', transform=ax7.transAxes)
        elif line.startswith(("1.", "2.")):
            ax7.text(0.5, y_pos, line, ha='center', va='top', fontsize=11,
                    fontweight='bold', color='#e74c3c', transform=ax7.transAxes)
        elif line.startswith(("3.", "4.")):
            ax7.text(0.5, y_pos, line, ha='center', va='top', fontsize=10,
                    color='#555', transform=ax7.transAxes)
        else:
            ax7.text(0.5, y_pos, line, ha='center', va='top', fontsize=10,
                    transform=ax7.transAxes)
        y_pos -= 0.15

    # Main title
    fig.suptitle('ZeroMQ Binding Performance Benchmark - Comprehensive Dashboard\nC++ (cppzmq) vs .NET (Net.Zmq) vs Node.js (zeromq.js)',
                fontsize=16, fontweight='bold', y=0.98)

    plt.tight_layout(rect=[0, 0, 1, 0.96])
    output_file = output_dir / "performance_dashboard.png"
    plt.savefig(output_file, dpi=300, bbox_inches="tight")
    print(f"  âœ“ Dashboard saved to: {output_file}")
    plt.close()


def main():
    """Main execution"""
    # Get project root
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    results_dir = project_root / "docs" / "results"

    # Load data
    json_file = results_dir / "benchmark_data.json"

    if not json_file.exists():
        print(f"Error: {json_file} not found")
        print("Run compare.py first to generate the data file")
        return 1

    print("Generating visualization plots...")
    print()

    with open(json_file, "r") as f:
        data = json.load(f)

    # Generate plots
    plot_latency_comparison(data, results_dir)
    plot_throughput_comparison(data, results_dir)
    plot_overhead_analysis(data, results_dir)
    plot_dashboard(data, results_dir)

    print()
    print("=" * 50)
    print("âœ“ All plots generated successfully!")
    print("=" * 50)
    print()
    print(f"Output directory: {results_dir}")
    print()

    return 0


if __name__ == "__main__":
    sys.exit(main())
